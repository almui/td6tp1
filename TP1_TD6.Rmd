---
title: "TP TD6"
output:
  html_document:
    df_print: paged
---

## **subir el dataset**

```{r }
datos <- read.csv("social_media_vs_productivity.csv")
```
Veamos si la base de datos contiene valores `NA`:

```{r}
table(is.na(datos))
```
## **limpiar el dataset**
En el caso de los datos del tiempo en redes sociales, horas de sueño, satisfacción de trabajo, tiempo en pantalla antes de dormir y nivel de estrés, los datos faltantes pueden sustituirse por el promedio (la cual es una métrica que no es muy sensible a datos atípicos).
En el caso del actual_productivity_score si deben eliminarse las filas con el dato faltable porque es la variable objetivo.Como tuvimos sufisientes observaciones decidimos sacar los datos faltantes para una mejor predicción. 
Redondeamos los parametros de actual y perceived productibity para que podemos transformarlo en parametros categoricos. Ademas agregamos una nueva columna para ver más facilmente quien es productivo y quien no. 

```{r}
library(dplyr)

sacar_na <- function(df) {
  # filtrar filas donde actual_productivity_score no sea NA
  df <- df %>%
    filter(!is.na(actual_productivity_score))

  # columnas que voy a cambiar los NA con el promdedio
  cols_to_impute <- c(
    "daily_social_media_time",
    "job_satisfaction_score",
    "sleep_hours",
    "screen_time_before_sleep",
    "stress_level",
    "perceived_productivity_score",
    ""
  )

  for (col in cols_to_impute) {
    if (col %in% names(df)) {
      mean_val <- mean(df[[col]], na.rm = TRUE)
      df[[col]][is.na(df[[col]])] <- mean_val
    }
  }
  return(df)
}
datos <- sacar_na(datos)
```
```{r}
# Redondeamos los parametros importantes

datos$stress_level <- as.integer(datos$stress_level)
datos$actual_productivity_score <- round(datos$actual_productivity_score, digits = 1)
datos$perceived_productivity_score <-round(datos$perceived_productivity_score, digits = 1)
datos$work_hours_per_day <- round(datos$work_hours_per_day, digits = 1)
datos$job_satisfaction_score <- round(datos$job_satisfaction_score , digits = 1)
datos$daily_social_media_time<- round(datos$daily_social_media_time, digits = 1)
datos$sleep_hours<- round(datos$sleep_hours, digits = 1)
datos$screen_time_before_sleep<- round(datos$screen_time_before_sleep, digits = 1)
datos$weekly_offline_hours<- round(datos$weekly_offline_hours, digits = 1)
# Agregamos una nueva columna que diga si fue productivo o no, es productivo si la productividad actual es mayor a 5
datos <- mutate(datos, es_productivo = ifelse(actual_productivity_score > 5.0, "SI", "NO"))

str(datos)

```
## Analisis estadistico
### **Variables cuantitativas** 
```{r}
summary(datos[, c("daily_social_media_time", "work_hours_per_day", "perceived_productivity_score", "actual_productivity_score", "stress_level", "job_satisfaction_score")])

var(datos$daily_social_media_time)
var(datos$work_hours_per_day) 
var(datos$perceived_productivity_score) 
var(datos$actual_productivity_score) 
var(datos$stress_level)
var(datos$job_satisfaction_score)
```
### **variables categoricas**

```{r}

table(datos$has_digital_wellbeing_enabled)

prop.table(table(datos$has_digital_wellbeing_enabled))

table(datos$es_productivo)

prop.table(table(datos$es_productivo))
```
## **Graficos**


```{r}
hist(datos$actual_productivity_score,main="Productividad real", col="skyblue")
```
```{r}

plot(datos$perceived_productivity_score, datos$actual_productivity_score, ylab="productividad real",xlab="productividad persivida",main="", xlim=c(0, 9), ylim=c(0, 11))
plot(datos$daily_social_media_time, datos$actual_productivity_score, ylab="productividad real",xlab="horas en las redes sociales",main="", xlim=c(0, 18), ylim=c(0, 11))
plot(datos$work_hours_per_day, datos$actual_productivity_score, ylab="productividad real", xlab="horas de trabajo",main="", xlim=c(0, 13), ylim=c(0, 11))
plot(datos$sleep_hours, datos$actual_productivity_score, ylab="productividad real", xlab="productividad real",main="", xlim=c(3, 10), ylim=c(0, 11))



```
## Dividir el data set
```{r}
set.seed(22)  # Semilla para que siempre salga igual si volvés a correrlo

datos <- datos %>% select(-actual_productivity_score)
datos <- datos %>% select(-perceived_productivity_score)


n <- nrow(datos)

# Mezclar aleatoriamente los índices
indices <- sample(1:n)

# Proporciones
n_train <- round(0.70 * n)
n_valid <- round(0.15 * n)
n_test  <- n - n_train - n_valid  # lo que quede

# Particiones
train_indices <- indices[1:n_train]
valid_indices <- indices[(n_train + 1):(n_train + n_valid)]
test_indices  <- indices[(n_train + n_valid + 1):n]

# Subsets finales
train <- datos[train_indices, ]
valid <- datos[valid_indices, ]
test  <- datos[test_indices, ]


```
```{r}
train
```
```{r}

train$has_digital_wellbeing_enabled<-as.factor(train$has_digital_wellbeing_enabled)
train$gender  <- as.factor(train$gender)
train$job_type <- as.factor(train$job_type)
train$social_platform_preference <- as.factor(train$social_platform_preference)
train$uses_focus_apps <- as.factor(train$uses_focus_apps)
# Convertir a factor
train$es_productivo <- factor(train$es_productivo)
test$es_productivo  <- factor(test$es_productivo)



```


```{r}
train
```
## Entrenar el modelo
```{r}
library(rpart)
#prueba

tree <- rpart(
  formula =  es_productivo ~ age + gender + job_type + daily_social_media_time + social_platform_preference + number_of_notifications + work_hours_per_day + stress_level + sleep_hours + screen_time_before_sleep + breaks_during_work + uses_focus_apps + has_digital_wellbeing_enabled + coffee_consumption_per_day + days_feeling_burnout_per_month + weekly_offline_hours + job_satisfaction_score,
  data = train,
  method = "class"
)


```
## Grafico del arbol 
```{r}
# install.packages("rpart.plot") # Descomentar si no lo tienen ya instalado.
library(rpart.plot)
rpart.plot(tree)

```
## Predicciones
```{r}

test$has_digital_wellbeing_enabled<-as.factor(test$has_digital_wellbeing_enabled)
test$gender  <- as.factor(test$gender)
test$job_type <- as.factor(test$job_type)
test$social_platform_preference <- as.factor(test$social_platform_preference)
test$uses_focus_apps <- as.factor(test$uses_focus_apps)

```
```{r}

predictions_prob  <- predict(tree, newdata = test, type="prob")
predictions_class <- predict(tree, newdata = test, type="class")
```
```{r}

predictions_prob
colnames(predictions_prob)
# probablemente sea "Sí" y "No", no "SI"

```
```{r}

# Accuracy
library(MLmetrics)

Accuracy(y_pred = predictions_class, y_true = test$es_productivo)

ConfusionMatrix(y_pred = predictions_class, y_true = test$es_productivo)



F1_Score(y_true=test$es_productivo, y_pred = predictions_class, positive = "SI")
Precision(y_true=test$es_productivo, y_pred = predictions_class, positive ="SI" )
Recall(y_true=test$es_productivo, y_pred = predictions_class, positive = "SI")
AUC(y_pred = predictions_prob[, "SI"],y_true = ifelse(test$es_productivo == "SI", 1, 0))
```
```{r}
library(caret)



ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,               # necesario para calcular probabilidades
  summaryFunction = twoClassSummary, # ROC/AUC
  savePredictions = "final"
)

grid <- expand.grid(maxdepth = 1:10)  # grid exhaustivo de maxdepth va a probar valores desde el 1 al 10






```

```{r}
minsplit_vals <- c(2, 5)
minbucket_vals <- c(1, 3)


optimizar_hp <-function(train,ctrl,grid, minsplit_vals, minbucket_vals){
  best <- data.frame(minsplit = 0,minbucket = 0,maxdepth = 0)
  best_ROC <- 0
  best_tree <- 0
  for(ms in minsplit_vals){
    for(mb in minbucket_vals){
      #temp para elegir el mejor maxdepth
      
      tree_temp <- train(
        es_productivo ~ .,
        data = train,
        method = "rpart2",
        trControl = ctrl,
        metric = "ROC",
        tuneGrid = grid,
        control = rpart.control(cp = 0, xval = 0, minsplit = ms, minbucket = mb)
      )
      
      
      temp_ROC <-  tree_temp$results$ROC[which.max(tree_temp$results$ROC)]
      if(best_ROC > temp_ROC){
        best_tree <-tree_temp
        best_ROC <-tree_temp$results$ROC
        best <- data.frame(minsplit = ms,minbucket = mb,maxdepth = tree_temp$bestTune$maxdepth)
      }
    }
  }
  return(best)
}


```

```{r}
optimizar_hp(train,ctrl,grid, minsplit_vals, minbucket_vals)
```
